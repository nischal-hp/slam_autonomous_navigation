# slam_autonomous_navigation
2D based Indoor SLAM and Autonomous Navigation using a Terrain ROBOT

RGB-D cameras (such as the Microsoft Kinect)
are novel sensing systems that capture RGB images along with
per-pixel depth information. In this paper we investigate how
such cameras can be used for building dense 2D maps of indoor
environments. Such maps have applications in robot navigation,
manipulation, semantic mapping, and telepresence. We present
RGB-D Mapping, a full 2D mapping system that utilizes a
novel joint optimization algorithm combining visual features
and shape-based alignment. Visual and depth information are
also combined for view-based loop-closure detection, followed
by pose optimization to achieve globally consistent maps. We
evaluate RGB-D Mapping on indoor environments, and show
that it effectively combines the visual and shape information
available from RGB-D cameras.
In the second part of the paper we develop a reactive navigation
system in which a mobile robot moves avoiding obstacles in
environment, using the distance sensor Kinect.
